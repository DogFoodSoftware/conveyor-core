<div id="Backup-Protocol" class="blurbSummary grid_12"
     data-perspective="implementation">
  <div class="blurbTitle">Backup Protocol</div>
  <div class="p">
    The backup protocol determine what gets backed up, when, and how. The
    answer to "what gets backed up" is "everything". With storage costs what
    they are, it's easier and cheaper to back up everything than to deal with
    the extra cost of trying to separate out bits and pieces.
  </div>
  <div class="p">
    To answer the 'when' and the 'how', we find it useful to break up the data
    into four groups:
    <ul>
      <li>physical host / distro software,</li>
      <li>physical host logs,</li>
      <li>Conveyor VMs, and</li>
      <li>Conveyor data.</li>
    </ul>
    This breaks the total 'universe of bits' into four categories which
    determine the method and options available. These being:
    <ul>
      <li>re-installation,</li>
      <li>disk level mirroring, and</li>
      <li>periodic snapshots.</li>
    </ul>
  </div>
  <div class="p">
    Of course, other bit-divisions and methods are possible and, in future may
    even be necessary. However, for the current goals, the proposed divisions
    and methods are deems sufficient in terms of functionality and minimal in
    terms of complexity.
  </div>
  <div class="subHeader"><span>Re-Installation</span></div>
  <div class="p">
    Re-installation means the bits are not explicitly backed up. Rather, we
    trust to the original installation as being reliable. Re-installation
    is&mdash;on it's own&mdash;is essentially incompatible with
    customization. It also presents problems where it is necessary to back up
    to a specific version as generally one would re-install and patch, and the
    patches available at the time of install may be newer than the patches
    last applied to the software being restored.
  </div>
  <div class="subHeader"><span>Disk Level Mirroring</span></div>
  <div class="p">
    Disk level mirroring, or RAID 1, creates a live copy of the disk. Under
    certain failure scenarios in which one hard drive detectably fails while
    the other remains operational, the 'mirrored' image remains functionally
    unaffected and the mirror array is able to operate normally, except that
    of course further failure cannot be tolerated.
  </div>
  <div class="p">
    Mirroring increases cost and complexity in order to make downtime more
    predictible. Depending on the hardware configuration and the nature of the
    error, mirroing may or may not increase overall uptime. That is, in the
    face of the clean failure of a disk, the first benefit is that one need
    not deal with the failure immediately because current operations array is
    not immediately effected. The disk still must be replaced (and as there
    are more disks, it's not clear that this creates less work), but the work
    need not be performed immediately and may be scheduled with greater
    flexibility.
  </div>
  <div class="p">
    It is possible to use disk arrays for other purposes, such as improved
    performance and as a tool to create large volumes. Given current
    mainstream technologies and our primary target market we opt
    to <a href="#Keep-It-Simple">keep it simple</a> and just consider the
    single, disk-to-disk mirroring
    scenario. <a href="#Future-Considerations">Future considerations</a> are
    discussed later.
  </div>
  <div id="Periodic-Snapshots" class="subHeader"><span>Periodic Snapshots</span></div>
    A periodic snapshot is just what it says. A snapshot of bits at a
    particular point in time. Snapshots may be taken at the volume or image
    level, or in a file-by-file manner.
  </div>
  <div class="p">
    A volume snapshot requires a compatible volume management system which can
    gurantee that all bits recorderd in the backup reflect the state of the
    volume as a whole at a given point in time even if some of the bits are
    changed before they are recorded. In the background, the volume manager
    tracks changes to volume bits in order to allow the original volume to
    continue functioning normally, but still provide a correct answer as to
    "what any given bit was" at the time of the snapshot to the backup.
  </div>
  <div class="p">
    Image snapshots work in a similar manner, but rather than a volume
    manager, the 'snapshot' capability is provided by the virtual machine
    manager, allowing one to take a consistent point-in-time snapshot of a
    running VM.
  </div>
  <div id="Disks-and-Volumes" class="subHeader"><span>Disks and Volumes</span></div>
  <div class="p">
    Disks are really big. At the sweet spot for $/byte for static drives is
    around 128-256GB. For 3.5, it's 3TB. For the majority of profitable web
    apps, that's more data than they need; and for many of them, capacity will
    improve faster than data accumulates.
  </div>
  <div class="p">
    Those kinds of volumes are big enough such that most environments will
    never need to create multi-drive volumes. As far as applications may
    utilize multi-volume data storage, even "big data" applications need not
    necessarily deal with multi-drive volumes, which reduces complexity.
  </div>
  <div class="p">
    The goal is to keep the backup policy simple for those that end up running
    their own physical machines in a production. Once you get into multi-drive
    volumes, you can't do disk-by-disk backup. As the fundamental physical
    unit of storage, the disk is itself the easiest thing to plan backups
    around.
  </div>
  <div class="subHeader"><span>RAID Policy</span></div>
  <div class="p">
    As discussed under <a href="#Disks-and-Volumes">Disks and
      Volumes</a>, there is often no need for multi-drive volumes in many
    environments. Which leaves 'performance' and 'reliability' as possible
    reasons to use RAID.
  </div>
  <div class="p">
    First, WRT to performance, SSDs are pretty fast. In fact, if you really
    need performance,
    it's <a href="http://www.mysqlperformanceblog.com/2010/01/18/fast-storage-8-ssd-intel-x-25m-80gb-benchmarks/">PCI-based
    SSDs you'll
    want</a>. Any RAID system adds significant complexity, and with
    SSDs <a href="http://research.microsoft.com/en-us/um/people/maheshba/papers/hotstorage09-raid.pdf">there's
    even more to worry about</a>. So start simple and move to RAID only if
    necessary. Remember, to benefit from a high performance ceiling, you need
    to be operating under sufficient demand to actually tax the
    system. Network transfer times are going to quast any micro-second
    improvements under unloaded scenarios. Many environments would not exhibit
    any observable benefits from a complex RAID system when compared to a
    single SSD volume.
  </div>
  <div class="p">
    So, what of reliability? Our own exeperience has been that unless actively
    maintained and monitored, RAID arrays are less reliable, due to their
    complexity and the additional failure point of the RAID card. With
    dedicated process and attention, RAID can be more reliable, but it's not a
    given.
  </div>
  <div class="p">
    In short, today's huge single drives and fast SSDs have raised the bar
    such that RAID is simply not necessary in many, if not most
    environments. RAID is not in-and-of-itself a particularly hard thing, but
    it does add yet another layer to the physical infrastructure and that much
    more complexity. We should be glad that in many situations, it's simply
    unnecessary.
  </div>
  <div class="subHeader"><span>Backing Up Physical Hosts; Distro and Logs</span></div>
  <div class="p">
    Backing up a Mac is easy. Use TimeMachine.
  </div>
  <div class="p">
    Dedicated Linux workstations should be laid out with a single root disk,
    partitioned into a straight ext4 root partition of 20GB for standard hosts
    and 10GB for shell-only servers (without a window manager). The remainder
    of the root disk should be as LVM storage generally partitioned into 2
    volumes: 1GB for the <code>/var</code> and the remainder
    for <code>/home</code> directories. Leave 1-2GB unallocated to support LVM
    snapshots. This allows the system logs and data to be backed up via volume
    snapshots. The remainder of the root file system is simply re-installed if
    the volume is lost.
  </div>
  <div class="subHeader"><span>Backing Up VMs</span></div>
  <div class="subHeader"><span>Backing Up Data Volumes</span></div>
</div><!-- .blurbSummary#Backup-Protocol -->

